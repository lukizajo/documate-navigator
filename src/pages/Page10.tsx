import { PageShell } from "@/components/PageShell";
import { MiniTest } from "@/components/ContentBlocks";
import { getNavContext } from "@/data/navigation";
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from "@/components/ui/table";

export default function Page10() {
  const nav = getNavContext("10-etika-ai-act");
  return (
    <PageShell
      title="ğŸ”Ÿ Etika, rizikÃ¡ a EÃš AI Act: ako pouÅ¾Ã­vaÅ¥ AI zodpovedne"
      {...nav}
    >
      <p><em>Toto je uzatvÃ¡racia ÄasÅ¥ M1. Vracia nÃ¡s spÃ¤Å¥ na zem a nastavuje zdravÃ© hranice pouÅ¾Ã­vania AI.</em></p>

      <h2>PreÄo je tÃ¡to sekcia dÃ´leÅ¾itÃ¡?</h2>
      <p>
        AI vie pÃ´sobiÅ¥ veÄ¾mi presvedÄivo. PrÃ¡ve preto je dÃ´leÅ¾itÃ© rozumieÅ¥ jej <strong>limitom, chybÃ¡m a rizikÃ¡m</strong>. ZodpovednÃ© pouÅ¾Ã­vanie AI nie je o strachu, ale o <strong>sprÃ¡vnom nastavenÃ­ oÄakÃ¡vanÃ­ a kontroly</strong>.
      </p>

      <h2>DÃ¡ta a sÃºkromie: Äo do AI nikdy nepatrÃ­! ğŸš«</h2>
      <p>Nikdy nezdieÄ¾aj:</p>
      <ul>
        <li>osobnÃ© Ãºdaje (PII)</li>
        <li>citlivÃ© firemnÃ© informÃ¡cie</li>
        <li>zdravotnÃ©, prÃ¡vne alebo finanÄnÃ© dÃ¡ta</li>
      </ul>
      <p>ğŸ‘‰ PlatÃ­ jednoduchÃ© pravidlo: <strong>ÄŒo by si neposlal cudziemu Äloveku, nedÃ¡vaj ani AI.</strong></p>

      <h2>Etika a hranice pouÅ¾Ã­vania âš–ï¸</h2>
      <p>AI je vhodnÃ¡ ako pomocnÃ­k pri:</p>
      <ul>
        <li>tvorbe obsahu</li>
        <li>brainstormingu</li>
        <li>sumarizÃ¡cii</li>
        <li>technickej podpore</li>
      </ul>
      <p>AI <strong>nie je vhodnÃ¡</strong> bez Ä¾udskej kontroly pri:</p>
      <ul>
        <li>medicÃ­nskych rozhodnutiach</li>
        <li>prÃ¡vnych radÃ¡ch</li>
        <li>finanÄnÃ½ch odporÃºÄaniach</li>
        <li>hodnotenÃ­ Ä¾udÃ­</li>
      </ul>
      <p>ğŸ‘‰ Ak mÃ´Å¾e chyba spÃ´sobiÅ¥ Å¡kodu, <strong>Älovek musÃ­ rozhodovaÅ¥</strong>.</p>

      <h2>ZodpovednÃ© pouÅ¾Ã­vanie v praxi âœ…</h2>
      <p>Pred pouÅ¾itÃ­m AI sa vÅ¾dy spÃ½taj:</p>
      <ul>
        <li>Potrebujem tu AI?</li>
        <li>Je vÃ½stup kritickÃ½?</li>
        <li>Viem ho overiÅ¥?</li>
        <li>Nesiem zaÅˆ zodpovednosÅ¥?</li>
      </ul>
      <p>Toto mentÃ¡lne nastavenie je dÃ´leÅ¾itejÅ¡ie neÅ¾ vÃ½ber nÃ¡stroja.</p>

      <h2>ZÃ¡kladnÃ½ princÃ­p EU AI Act:</h2>
      <p>RegulÃ¡cia je postavenÃ¡ na rizikovom prÃ­stupe â€“ ÄÃ­m vÃ¤ÄÅ¡ie riziko pre Ä¾udÃ­ a spoloÄnosÅ¥, tÃ½m prÃ­snejÅ¡ie pravidlÃ¡.</p>
      <p>NiektorÃ© praktiky sÃº zakÃ¡zanÃ© Ãºplne, inÃ© podliehajÃº prÃ­snym kontrolÃ¡m a transparentnosti.</p>
      <p>CieÄ¾om EU AI Act nie je zastaviÅ¥ inovÃ¡cie, ale nastaviÅ¥ jasnÃ© hranice, aby sa AI pouÅ¾Ã­vala bezpeÄne, fÃ©rovo a zodpovedne.</p>

      <h3>ğŸš¥ Rozdelenie AI podÄ¾a rizika</h3>

      <h3>ğŸš« ZakÃ¡zanÃ© praktiky (Unacceptable risk)</h3>
      <p>Tieto systÃ©my sÃº Ãºplne zakÃ¡zanÃ©, bez vÃ½nimiek:</p>
      <ul>
        <li><strong>manipulÃ¡cia</strong> sprÃ¡vania Ä¾udÃ­ (napr. zraniteÄ¾nÃ½ch skupÃ­n),</li>
        <li><strong>sociÃ¡lne skÃ³rovanie</strong> obÄanov,</li>
        <li><strong>rozpoznÃ¡vanie emÃ³ciÃ­</strong> v Å¡kolÃ¡ch a na pracoviskÃ¡ch,</li>
        <li>niektorÃ© formy <strong>biometrickej identifikÃ¡cie</strong> v reÃ¡lnom Äase.</li>
      </ul>
      <p>ğŸ‘‰ Pokuty aÅ¾ <strong>35 miliÃ³nov â‚¬</strong> alebo <strong>7 %</strong> celosvetovÃ©ho roÄnÃ©ho obratu (podÄ¾a toho, Äo je vyÅ¡Å¡ie).</p>

      <h3>âš ï¸ VysokorizikovÃ© systÃ©my (High-risk AI)</h3>
      <p><strong>PovolenÃ©, ale prÃ­sne regulovanÃ©.</strong> Patria sem AI systÃ©my pouÅ¾Ã­vanÃ© naprÃ­klad v:</p>
      <ul>
        <li>zdravotnÃ­ctve,</li>
        <li>vzdelÃ¡vanÃ­,</li>
        <li>nÃ¡bore zamestnancov,</li>
        <li>bankovnÃ­ctve a Ãºveroch,</li>
        <li>kritickej infraÅ¡truktÃºre,</li>
        <li>verejnej sprÃ¡ve.</li>
      </ul>
      <p><strong>Povinnosti:</strong></p>
      <ul>
        <li>kvalitnÃ© a nediskriminaÄnÃ© dÃ¡ta,</li>
        <li>dokumentÃ¡cia a vysvetliteÄ¾nosÅ¥,</li>
        <li>Ä¾udskÃ½ dohÄ¾ad,</li>
        <li>riadenie rizÃ­k a testovanie.</li>
      </ul>
      <p>ğŸ‘‰ Pokuty do <strong>15 miliÃ³nov â‚¬</strong> alebo <strong>3 %</strong> celosvetovÃ©ho obratu.</p>

      <h3>â— ObmedzenÃ© riziko (Limited risk)</h3>
      <p>Sem patria najmÃ¤:</p>
      <ul>
        <li>chatboty,</li>
        <li>generovanie textu, obrazu, hlasu.</li>
      </ul>
      <p>PovinnosÅ¥ou je transparentnosÅ¥:</p>
      <ul>
        <li>pouÅ¾Ã­vateÄ¾ musÃ­ vedieÅ¥, Å¾e komunikuje s AI,</li>
        <li>pri generovanom obsahu mÃ¡ byÅ¥ jasne oznaÄenÃ©, Å¾e je vytvorenÃ½ AI.</li>
      </ul>
      <p>ğŸ‘‰ Pokuty do <strong>7,5 miliÃ³na â‚¬</strong> alebo <strong>1,5 %</strong> obratu.</p>

      <h3>âœ… MinimÃ¡lne riziko (Minimal risk)</h3>
      <p>BeÅ¾nÃ© AI pouÅ¾itie:</p>
      <ul>
        <li>odporÃºÄacie algoritmy,</li>
        <li>filtrovanie spamu,</li>
        <li>hernÃ© AI,</li>
        <li>zÃ¡kladnÃ© AI funkcie v aplikÃ¡ciÃ¡ch.</li>
      </ul>
      <p>ğŸ‘‰ Bez novÃ½ch povinnostÃ­, len dobrovoÄ¾nÃ© etickÃ© odporÃºÄania.</p>

      <h2>ÄŒasovÃ¡ os EU AI Act:</h2>
      <Table>
        <TableHeader>
          <TableRow>
            <TableHead>DÃ¡tum</TableHead>
            <TableHead>UdalosÅ¥</TableHead>
          </TableRow>
        </TableHeader>
        <TableBody>
          <TableRow><TableCell>21. 4. 2021</TableCell><TableCell>EurÃ³pska komisia predstavuje nÃ¡vrh EU AI Act</TableCell></TableRow>
          <TableRow><TableCell>8. 12. 2023</TableCell><TableCell>PolitickÃ¡ dohoda medzi EK, Radou EÃš a EP</TableCell></TableRow>
          <TableRow><TableCell>13. 3. 2024</TableCell><TableCell>SchvÃ¡lenie EU AI Act EurÃ³pskym parlamentom</TableCell></TableRow>
          <TableRow><TableCell>21. 5. 2024</TableCell><TableCell>FormÃ¡lne prijatie Radou EÃš</TableCell></TableRow>
          <TableRow><TableCell>12. 7. 2024</TableCell><TableCell>Zverejnenie v Ãšradnom vestnÃ­ku EÃš</TableCell></TableRow>
          <TableRow><TableCell>1. 8. 2024</TableCell><TableCell>Nadobudnutie platnosti (zaÄiatok prechodnÃ½ch obdobÃ­)</TableCell></TableRow>
          <TableRow><TableCell>2. 2. 2025</TableCell><TableCell>ZÃ¡kaz neprijateÄ¾nÃ½ch praktÃ­k (sociÃ¡lne skÃ³rovanie, manipulÃ¡cia, rozpoznÃ¡vanie emÃ³ciÃ­ na pracoviskÃ¡ch a v Å¡kolÃ¡ch)</TableCell></TableRow>
          <TableRow><TableCell>2. 8. 2025</TableCell><TableCell>Povinnosti pre generatÃ­vne a GPAI modely + AI gramotnosÅ¥</TableCell></TableRow>
          <TableRow><TableCell>2. 8. 2026</TableCell><TableCell>PlnÃ¡ ÃºÄinnosÅ¥ pre vysokorizikovÃ© AI systÃ©my</TableCell></TableRow>
        </TableBody>
      </Table>

      <p className="mt-4">EU AI Act nevychÃ¡dza zo strachu z AI, ale z reality.</p>
      <p>ÄŒÃ­m vÃ¤ÄÅ¡Ã­ dopad mÃ´Å¾e maÅ¥ chyba AI na Äloveka, tÃ½m prÃ­snejÅ¡ie pravidlÃ¡ platia.</p>

      <h2>ÄŒo si z tejto sekcie odniesÅ¥? ğŸ¯</h2>
      <ul>
        <li>AI nie je neomylnÃ¡</li>
        <li>presvedÄivosÅ¥ nie je dÃ´kaz pravdy</li>
        <li>zodpovednosÅ¥ zostÃ¡va vÅ¾dy na Äloveku</li>
        <li>etika nie je voliteÄ¾nÃ¡ vÃ½bava</li>
      </ul>
      <p>ğŸ‘‰ <strong>AI asistuje. ÄŒlovek rozhoduje.</strong></p>

      <MiniTest
        question="KtorÃ© pouÅ¾itie AI je najzodpovednejÅ¡ie z pohÄ¾adu sÃºkromia? SituÃ¡cia: ChceÅ¡ si uÄ¾ahÄiÅ¥ prÃ¡cu a pouÅ¾iÅ¥ AI, ale nechceÅ¡ zdieÄ¾aÅ¥ niÄ citlivÃ©. Vyber, ktorÃ¡ moÅ¾nosÅ¥ (ğŸŒ• /â­ /â˜€ï¸) je najlepÅ¡ia."
        options={[
          { label: "ğŸŒ•", text: 'â€PrepÃ­Å¡em problÃ©m do AI bez osobnÃ½ch Ãºdajov (bez mien, adries, ÄÃ­sel, internÃ½ch citlivÃ½ch info). Ak potrebujem prÃ­klad, pouÅ¾ijem vymyslenÃ© Ãºdaje alebo anonymizÃ¡ciu."' },
          { label: "â­", text: 'â€HodÃ­m do AI screenshot dokumentu, kde sÃº osobnÃ© Ãºdaje. VeÄ je to len na chvÃ­Ä¾u a nikto to neuvidÃ­."' },
          { label: "â˜€ï¸", text: 'â€SkopÃ­rujem do AI celÃ½ e-mail od zÃ¡kaznÃ­ka aj s menom, adresou a ÄÃ­slom objednÃ¡vky, nech mi z toho spravÃ­ odpoveÄ."' },
        ]}
        correct="ğŸŒ•"
        explanation="PlatÃ­ jednoduchÃ© pravidlo â€” Äo by si neposlal cudziemu Äloveku, nedÃ¡vaj ani AI. CitlivÃ© Ãºdaje treba odstrÃ¡niÅ¥ alebo anonymizovaÅ¥."
      />
    </PageShell>
  );
}
