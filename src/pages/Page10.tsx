import { PageShell } from "@/components/PageShell";
import { MiniTest } from "@/components/ContentBlocks";
import { getNavContext } from "@/data/navigation";
import { Table, TableBody, TableCell, TableHead, TableHeader, TableRow } from "@/components/ui/table";

export default function Page10() {
  const nav = getNavContext("10-etika-ai-act");
  return (
    <PageShell
      title="ğŸ”Ÿ Etika, rizikÃ¡ a EU AI Act"
      tldr={[
        "Do AI nikdy nedÃ¡vaj osobnÃ© Ãºdaje, citlivÃ© firemnÃ© ani zdravotnÃ© dÃ¡ta",
        "Ak mÃ´Å¾e chyba spÃ´sobiÅ¥ Å¡kodu, Älovek musÃ­ rozhodovaÅ¥",
        "EU AI Act reguluje AI podÄ¾a rizikovÃ©ho prÃ­stupu â€“ 4 kategÃ³rie",
        "NiektorÃ© AI praktiky sÃº Ãºplne zakÃ¡zanÃ© (sociÃ¡lne skÃ³rovanie, manipulÃ¡cia)",
        "AI asistuje. ÄŒlovek rozhoduje.",
      ]}
      {...nav}
    >
      <h2>âš ï¸ PreÄo je tÃ¡to sekcia dÃ´leÅ¾itÃ¡?</h2>
      <p>
        AI vie pÃ´sobiÅ¥ veÄ¾mi presvedÄivo. PrÃ¡ve preto je dÃ´leÅ¾itÃ© rozumieÅ¥ jej limitom, chybÃ¡m a rizikÃ¡m.
        ZodpovednÃ© pouÅ¾Ã­vanie AI nie je o strachu, ale o sprÃ¡vnom nastavenÃ­ oÄakÃ¡vanÃ­ a kontroly.
      </p>

      <h2>ğŸš« DÃ¡ta a sÃºkromie: Äo do AI nikdy nepatrÃ­!</h2>
      <p>Nikdy nezdieÄ¾aj:</p>
      <ul>
        <li>osobnÃ© Ãºdaje (PII)</li>
        <li>citlivÃ© firemnÃ© informÃ¡cie</li>
        <li>zdravotnÃ©, prÃ¡vne alebo finanÄnÃ© dÃ¡ta</li>
      </ul>
      <p>ğŸ‘‰ PlatÃ­ jednoduchÃ© pravidlo: ÄŒo by si neposlal cudziemu Äloveku, nedÃ¡vaj ani AI.</p>

      <h2>âš–ï¸ Etika a hranice pouÅ¾Ã­vania</h2>
      <p>AI je vhodnÃ¡ ako pomocnÃ­k pri:</p>
      <ul>
        <li>tvorbe obsahu</li>
        <li>brainstormingu</li>
        <li>sumarizÃ¡cii</li>
        <li>technickej podpore</li>
      </ul>
      <p>AI nie je vhodnÃ¡ bez Ä¾udskej kontroly pri:</p>
      <ul>
        <li>medicÃ­nskych rozhodnutiach</li>
        <li>prÃ¡vnych radÃ¡ch</li>
        <li>finanÄnÃ½ch odporÃºÄaniach</li>
        <li>hodnotenÃ­ Ä¾udÃ­</li>
      </ul>
      <p>ğŸ‘‰ Ak mÃ´Å¾e chyba spÃ´sobiÅ¥ Å¡kodu, Älovek musÃ­ rozhodovaÅ¥.</p>

      <h2>âœ… ZodpovednÃ© pouÅ¾Ã­vanie v praxi</h2>
      <p>Pred pouÅ¾itÃ­m AI sa vÅ¾dy spÃ½taj:</p>
      <ul>
        <li>Potrebujem tu AI?</li>
        <li>Je vÃ½stup kritickÃ½?</li>
        <li>Viem ho overiÅ¥?</li>
        <li>Nesiem zaÅˆ zodpovednosÅ¥?</li>
      </ul>
      <p>Toto mentÃ¡lne nastavenie je dÃ´leÅ¾itejÅ¡ie neÅ¾ vÃ½ber nÃ¡stroja.</p>

      <h2>ğŸ‡ªğŸ‡º EU AI Act</h2>
      <p>
        RegulÃ¡cia je postavenÃ¡ na rizikovom prÃ­stupe â€“ ÄÃ­m vÃ¤ÄÅ¡ie riziko pre Ä¾udÃ­ a spoloÄnosÅ¥,
        tÃ½m prÃ­snejÅ¡ie pravidlÃ¡. CieÄ¾om EU AI Act nie je zastaviÅ¥ inovÃ¡cie, ale nastaviÅ¥ jasnÃ© hranice.
      </p>

      <h3>ğŸš¥ Rozdelenie AI podÄ¾a rizika</h3>

      <h3>ğŸš« ZakÃ¡zanÃ© praktiky (Unacceptable risk)</h3>
      <p>Ãšplne zakÃ¡zanÃ©, bez vÃ½nimiek:</p>
      <ul>
        <li>manipulÃ¡cia sprÃ¡vania Ä¾udÃ­ (napr. zraniteÄ¾nÃ½ch skupÃ­n)</li>
        <li>sociÃ¡lne skÃ³rovanie obÄanov</li>
        <li>rozpoznÃ¡vanie emÃ³ciÃ­ v Å¡kolÃ¡ch a na pracoviskÃ¡ch</li>
        <li>niektorÃ© formy biometrickej identifikÃ¡cie v reÃ¡lnom Äase</li>
      </ul>
      <p>ğŸ‘‰ Pokuty aÅ¾ 35 miliÃ³nov â‚¬ alebo 7 % celosvetovÃ©ho roÄnÃ©ho obratu.</p>

      <h3>âš ï¸ VysokorizikovÃ© systÃ©my (High-risk AI)</h3>
      <p>PovolenÃ©, ale prÃ­sne regulovanÃ©. Patria sem AI v:</p>
      <ul>
        <li>zdravotnÃ­ctve, vzdelÃ¡vanÃ­, nÃ¡bore zamestnancov</li>
        <li>bankovnÃ­ctve a Ãºveroch</li>
        <li>kritickej infraÅ¡truktÃºre, verejnej sprÃ¡ve</li>
      </ul>
      <p>Povinnosti: kvalitnÃ© dÃ¡ta, dokumentÃ¡cia a vysvetliteÄ¾nosÅ¥, Ä¾udskÃ½ dohÄ¾ad, riadenie rizÃ­k.</p>
      <p>ğŸ‘‰ Pokuty do 15 miliÃ³nov â‚¬ alebo 3 % celosvetovÃ©ho obratu.</p>

      <h3>â— ObmedzenÃ© riziko (Limited risk)</h3>
      <p>Chatboty, generovanie textu, obrazu, hlasu. PovinnosÅ¥ou je transparentnosÅ¥:</p>
      <ul>
        <li>pouÅ¾Ã­vateÄ¾ musÃ­ vedieÅ¥, Å¾e komunikuje s AI</li>
        <li>generovanÃ½ obsah mÃ¡ byÅ¥ jasne oznaÄenÃ½</li>
      </ul>
      <p>ğŸ‘‰ Pokuty do 7,5 miliÃ³na â‚¬ alebo 1,5 % obratu.</p>

      <h3>âœ… MinimÃ¡lne riziko (Minimal risk)</h3>
      <p>BeÅ¾nÃ© AI pouÅ¾itie: odporÃºÄacie algoritmy, filtrovanie spamu, hernÃ© AI.</p>
      <p>ğŸ‘‰ Bez novÃ½ch povinnostÃ­, len dobrovoÄ¾nÃ© etickÃ© odporÃºÄania.</p>

      <h2>ğŸ“… ÄŒasovÃ¡ os EU AI Act</h2>
      <Table>
        <TableHeader>
          <TableRow>
            <TableHead>DÃ¡tum</TableHead>
            <TableHead>UdalosÅ¥</TableHead>
          </TableRow>
        </TableHeader>
        <TableBody>
          <TableRow><TableCell>1.4.2021</TableCell><TableCell>EurÃ³pska komisia predstavuje nÃ¡vrh EU AI Act</TableCell></TableRow>
          <TableRow><TableCell>8.12.2023</TableCell><TableCell>PolitickÃ¡ dohoda medzi EK, Radou EÃš a EP</TableCell></TableRow>
          <TableRow><TableCell>13.3.2024</TableCell><TableCell>SchvÃ¡lenie EU AI Act EurÃ³pskym parlamentom</TableCell></TableRow>
          <TableRow><TableCell>21.5.2024</TableCell><TableCell>FormÃ¡lne prijatie Radou EÃš</TableCell></TableRow>
          <TableRow><TableCell>12.7.2024</TableCell><TableCell>Zverejnenie v Ãšradnom vestnÃ­ku EÃš</TableCell></TableRow>
          <TableRow><TableCell>1.8.2024</TableCell><TableCell>Nadobudnutie platnosti</TableCell></TableRow>
          <TableRow><TableCell>2.2.2025</TableCell><TableCell>ZÃ¡kaz neprijateÄ¾nÃ½ch praktÃ­k</TableCell></TableRow>
          <TableRow><TableCell>2.8.2025</TableCell><TableCell>Povinnosti pre generatÃ­vne a GPAI modely + AI gramotnosÅ¥</TableCell></TableRow>
          <TableRow><TableCell>2.8.2026</TableCell><TableCell>PlnÃ¡ ÃºÄinnosÅ¥ pre vysokorizikovÃ© AI systÃ©my</TableCell></TableRow>
        </TableBody>
      </Table>

      <p className="mt-4">EU AI Act nevychÃ¡dza zo strachu z AI, ale z reality. ÄŒÃ­m vÃ¤ÄÅ¡Ã­ dopad mÃ´Å¾e maÅ¥ chyba AI na Äloveka, tÃ½m prÃ­snejÅ¡ie pravidlÃ¡ platia.</p>

      <h2>ğŸ¯ ÄŒo si z tejto sekcie odniesÅ¥?</h2>
      <ul>
        <li>AI nie je neomylnÃ¡</li>
        <li>presvedÄivosÅ¥ nie je dÃ´kaz pravdy</li>
        <li>zodpovednosÅ¥ zostÃ¡va vÅ¾dy na Äloveku</li>
        <li>etika nie je voliteÄ¾nÃ¡ vÃ½bava</li>
      </ul>
      <p>ğŸ‘‰ AI asistuje. ÄŒlovek rozhoduje.</p>

      <MiniTest
        question="KtorÃ© pouÅ¾itie AI je najzodpovednejÅ¡ie z pohÄ¾adu sÃºkromia? SituÃ¡cia: ChceÅ¡ si uÄ¾ahÄiÅ¥ prÃ¡cu a pouÅ¾iÅ¥ AI, ale nechceÅ¡ zdieÄ¾aÅ¥ niÄ citlivÃ©."
        options={[
          { label: "ğŸŒ•", text: 'â€PrepÃ­Å¡em problÃ©m do AI bez osobnÃ½ch Ãºdajov. Ak potrebujem prÃ­klad, pouÅ¾ijem vymyslenÃ© Ãºdaje alebo anonymizÃ¡ciu."' },
          { label: "â­", text: 'â€HodÃ­m do AI screenshot dokumentu s osobnÃ½mi Ãºdajmi. VeÄ je to len na chvÃ­Ä¾u."' },
        ]}
        correct="ğŸŒ•"
        explanation="PlatÃ­ jednoduchÃ© pravidlo â€” Äo by si neposlal cudziemu Äloveku, nedÃ¡vaj ani AI. CitlivÃ© Ãºdaje treba odstrÃ¡niÅ¥ alebo anonymizovaÅ¥."
      />
    </PageShell>
  );
}
